/**
 * FLUX Framework UAT Testing - Main Command Handler
 * @module @voilajsx/flux/scripts/commands/uat
 * @file scripts/commands/uat.js
 *
 * @llm-rule WHEN: Coordinating UAT test case generation and execution
 * @llm-rule AVOID: Business logic - delegate to helpers for maintainability
 * @llm-rule NOTE: Main entry point that imports and delegates to helper modules
 */

import { createLogger } from '../logger.js';
import {
  generateAllFeatureTestCases,
  generateFeatureTestCases,
} from '../helpers/generateTestCase.js';
import { runFeatureTests, runAllFeatureTests } from '../helpers/runTestCase.js';

const log = createLogger('uat');

/**
 * UAT testing command for FLUX Framework endpoints
 * @llm-rule WHEN: Generating test cases or running UAT tests
 * @llm-rule AVOID: Implementing business logic here - use helpers
 * @llm-rule NOTE: npm run flux:uat generate:feature [--overwrite] OR npm run flux:uat run:feature [--restart]
 *
 * Examples:
 * - npm run flux:uat generate:weather                    # Generate Excel test cases (timestamped)
 * - npm run flux:uat generate:weather --overwrite       # Generate Excel test cases (overwrite existing)
 * - npm run flux:uat generate:all                        # Generate test cases for all features
 * - npm run flux:uat run:weather                        # Run UAT tests against localhost:3000
 * - npm run flux:uat run:weather --restart              # Restart UAT execution from beginning
 * - npm run flux:uat run:all                            # Run all features against localhost:3000
 */
export default async function uat(args) {
  const startTime = Date.now();

  if (!args || args.length === 0) {
    showUATHelp();
    return false;
  }

  // Parse command and target
  const command = args[0]; // generate:weather or run:weather
  const [action, target] = command.split(':');

  if (!['generate', 'run'].includes(action)) {
    console.log('âŒ Invalid action. Use generate:feature or run:feature');
    return false;
  }

  if (!target) {
    console.log('âŒ Target required. Use generate:weather or run:weather');
    return false;
  }

  // Parse flags
  const hasOverwrite = args.includes('--overwrite');
  const hasRestart = args.includes('--restart');

  try {
    if (action === 'generate') {
      return await handleGenerateCommand(target, hasOverwrite, startTime);
    } else {
      return await handleRunCommand(target, hasRestart, startTime);
    }
  } catch (error) {
    console.log(`âŒ UAT ${action} error: ${error.message}`);
    return false;
  }
}

/**
 * Handle generate command for UAT test cases
 * @param {string} target - Target feature or 'all'
 * @param {boolean} overwrite - Whether to overwrite existing files
 * @param {number} startTime - Command start timestamp
 * @returns {Promise<boolean>} Success status
 */
async function handleGenerateCommand(target, overwrite, startTime) {
  log.info(`ğŸ“‹ Generating UAT test cases for ${target}`);

  const results = [];

  if (target === 'all') {
    // Generate test cases for all features
    results.push(...(await generateAllFeatureTestCases(overwrite)));
  } else {
    // Generate test cases for specific feature
    results.push(await generateFeatureTestCases(target, overwrite));
  }

  // Report results
  const duration = Date.now() - startTime;
  const successful = results.filter((r) => r.success).length;
  const total = results.length;

  if (successful === total) {
    console.log(
      `âœ… UAT test cases generated (${successful}/${total}) ${duration}ms`
    );

    results.forEach((result) => {
      console.log(`   ğŸ“Š ${result.excelFile}`);
      console.log(`      ${result.testCasesGenerated} test cases created`);
      if (result.wasOverwritten) {
        console.log(`      âš ï¸  Existing file was overwritten`);
      }
    });

    console.log(`\nğŸ’¡ Next steps:`);
    console.log(`   1. Review Excel files in __uat__ folders`);
    console.log(`   2. Customize test data if needed`);
    console.log(`   3. Run tests: npm run flux:uat run:${target}`);

    return true;
  } else {
    console.log(
      `âŒ UAT test case generation failed (${successful}/${total}) ${duration}ms`
    );

    results
      .filter((r) => !r.success)
      .forEach((result) => {
        console.log(`   âŒ ${result.feature}: ${result.error}`);
      });

    return false;
  }
}

/**
 * Handle run command for UAT test execution
 * @param {string} target - Target feature or 'all'
 * @param {boolean} restart - Whether to restart from beginning
 * @param {number} startTime - Command start timestamp
 * @returns {Promise<boolean>} Success status
 */
async function handleRunCommand(target, restart, startTime) {
  log.info(`ğŸ§ª Running UAT tests for ${target} on localhost:3000`);

  const results = [];

  try {
    if (target === 'all') {
      // Run tests for all features
      results.push(...(await runAllFeatureTests(restart)));
    } else {
      // Run tests for specific feature
      results.push(await runFeatureTests(target, restart));
    }

    // Report results
    const duration = Date.now() - startTime;
    const successful = results.filter((r) => r.success).length;
    const total = results.length;

    if (successful === total) {
      console.log(
        `âœ… UAT test execution completed (${successful}/${total}) ${duration}ms`
      );

      results.forEach((result) => {
        console.log(`   ğŸ§ª ${result.feature}: ${result.status}`);
        console.log(`      Tests run: ${result.testsRun}`);
        console.log(`      Passed: ${result.testsPassed}`);
        if (result.testsFailed > 0) {
          console.log(`      Failed: ${result.testsFailed} âš ï¸`);
        }
        if (result.excelFile) {
          console.log(`      Excel updated: ${result.excelFile}`);
        }
      });

      return true;
    } else {
      console.log(
        `âŒ UAT test execution failed (${successful}/${total}) ${duration}ms`
      );

      results
        .filter((r) => !r.success)
        .forEach((result) => {
          console.log(`   âŒ ${result.feature}: ${result.status}`);
          if (result.error) {
            console.log(`      Error: ${result.error}`);
          }
        });

      return false;
    }
  } catch (error) {
    console.log(`âŒ UAT execution error: ${error.message}`);
    return false;
  }
}

/**
 * Show UAT command help and usage examples
 * @llm-rule WHEN: User provides invalid arguments or requests help
 * @llm-rule AVOID: Verbose help - keep focused on essential usage
 * @llm-rule NOTE: Shows comprehensive usage patterns and workflow
 */
function showUATHelp() {
  console.log(`
ğŸ§ª FLUX UAT Testing - Excel-Based User Acceptance Testing

GENERATE PHASE:
  npm run flux:uat generate:weather              # Generate Excel test cases (timestamped)
  npm run flux:uat generate:weather --overwrite # Generate Excel test cases (overwrite existing)
  npm run flux:uat generate:all                 # Generate test cases for all features

RUN PHASE:
  npm run flux:uat run:weather                   # Execute tests against localhost:3000
  npm run flux:uat run:weather --restart        # Restart execution from beginning
  npm run flux:uat run:all                       # Execute all features against localhost:3000
  npm run flux:uat run:all --restart            # Restart all features from beginning

WHAT IT CREATES:
  Generate Phase:
  - src/api/{feature}/__uat__/{feature}.testcases_YYYYMMDDHHMMSS.xlsx (timestamped)
  - src/api/{feature}/__uat__/{feature}.testcases.xlsx (overwrite mode)
  
  Run Phase:
  - Updates Excel files with test results and color coding
  - Creates {feature}.execution.state.json for resumable execution
  - Live browser automation with visual feedback

EXCEL STRUCTURE:
  - Test Cases Sheet: Comprehensive test scenarios targeting localhost:3000
  - Environment Config Sheet: Local development settings
  - Summary Sheet: Test statistics and overview

EXECUTION FEATURES:
  âœ… Visual browser automation with Playwright (Chromium)
  âœ… Live Excel updates with color-coded results
  âœ… Resumable execution - automatically continues from last failed test
  âœ… Row color coding: White (pending), Yellow (running), Green (pass), Red (fail)
  âœ… Execution state tracking with .state.json files
  âœ… Real-time progress reporting
  âœ… Automatic halt on first failure with recovery instructions

SPECIFICATION-DRIVEN TESTING:
  âœ… Test cases from specification.endpoints[endpoint].test.test_cases
  âœ… Real test data extracted from test case paths  
  âœ… Parameter replacement: /api/weather/:city â†’ /api/weather/mumbai
  âœ… Security tests: XSS, SQL injection, input validation
  âœ… Edge cases: Unicode, encoding, boundary conditions

TEST CATEGORIES:
  ğŸ“— Happy Path: Successful scenarios with valid data
  ğŸ“™ Validation: Input validation rules from specification
  ğŸ“• Security: XSS, SQL injection, malicious input protection  
  ğŸ“˜ Error Handling: External API failures and timeouts
  ğŸ“” Edge Cases: Unicode, encoding, boundary conditions

EXAMPLE WORKFLOW:
  1. npm run flux:uat generate:weather
  2. Open src/api/weather/__uat__/weather.testcases_YYYYMMDDHHMMSS.xlsx
  3. Review test cases (paths with actual values, not :parameters)
  4. Customize test data for query parameters if needed
  5. npm run flux:uat run:weather
  6. Watch browser automation execute tests with live Excel updates
  7. Fix any failures and resume with npm run flux:uat run:weather

RESUMABLE EXECUTION:
  ğŸ”„ Execution automatically saves state after each test
  ğŸ”„ If execution halts due to failure, simply run the same command to resume
  ğŸ”„ Use --restart flag to start fresh and ignore saved state
  ğŸ”„ State files stored as {feature}.execution.state.json in __uat__ folders

BROWSER AUTOMATION:
  ğŸŒ Uses visible Chromium browser with 500ms slow motion
  ğŸŒ Real-time test case titles shown in browser
  ğŸŒ 2-second delays between tests for visual feedback
  ğŸŒ Automatic network waiting and timeout handling
  ğŸŒ Supports both GET and POST/PUT/DELETE requests

EXCEL COLOR CODING:
  âšª White: Test pending execution
  ğŸŸ¡ Yellow: Test currently running
  ğŸŸ¢ Green: Test passed successfully
  ğŸ”´ Red: Test failed with error details
  ğŸŸ£ Purple: Test skipped

ENVIRONMENT:
  All UAT tests run against: http://localhost:3000
  Perfect for agent-driven development and testing

FILE ORGANIZATION:
  src/api/weather/
  â”œâ”€â”€ __uat__/                                    # UAT test files
  â”‚   â”œâ”€â”€ weather.testcases_20250730104002.xlsx   # Timestamped generations
  â”‚   â”œâ”€â”€ weather.testcases_20250730105534.xlsx   # Multiple versions preserved
  â”‚   â”œâ”€â”€ weather.testcases.xlsx                  # Overwrite mode (--overwrite)
  â”‚   â””â”€â”€ weather.execution.state.json            # Execution state for resuming
  â”œâ”€â”€ main/                                       # Feature implementation
  â”œâ”€â”€ @city/
  â”œâ”€â”€ weather.specification.json                 # Source for test cases
  â””â”€â”€ weather.requirements.yml

SECURITY TESTS INCLUDED:
  ğŸ›¡ï¸  XSS Protection: Script tags, image tags, event handlers
  ğŸ›¡ï¸  SQL Injection: DROP tables, UNION selects, OR conditions
  ğŸ›¡ï¸  Input Validation: Empty inputs, extremely long inputs
  ğŸ›¡ï¸  Special Characters: Null bytes, control characters
  ğŸ›¡ï¸  Encoding Attacks: URL encoding bypass attempts
  ğŸ›¡ï¸  Boundary Values: Negative numbers, integer overflow

RECOVERY FROM FAILURES:
  When a test fails, execution continues to test all remaining cases.
  Failed tests are marked with red backgrounds in Excel.
  Only system errors (browser crashes, file issues) halt execution.
  
  System Error Recovery:
  - Fix the underlying system issue (browser, file permissions, etc.)
  - Run: npm run flux:uat run:feature (resumes from last successful test)
  
  Test Failure Review:
  - All test failures are recorded in Excel with red backgrounds
  - Review failed tests and fix issues in your API implementation
  - Re-run tests to verify fixes: npm run flux:uat run:feature

PERFORMANCE FEATURES:
  âš¡ Smart Excel file discovery (uses latest timestamped file)
  âš¡ Efficient browser reuse across test cases
  âš¡ Minimal memory footprint with streaming Excel updates
  âš¡ Parallel execution support for multiple features (run:all)
`);
}
